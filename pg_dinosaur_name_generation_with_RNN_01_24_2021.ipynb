{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pg_dinosaur_name_generation_with_RNN-01-24-2021.ipynb",
      "provenance": [],
      "mount_file_id": "16fIlOrgvSiMs1PC81mmlaGgF6pXlvWxj",
      "authorship_tag": "ABX9TyMpmGSlRM30sepbi/+qml+g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phanigundubogula/dl_projects/blob/master/pg_dinosaur_name_generation_with_RNN_01_24_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwxkEw95iDSQ",
        "outputId": "ad002242-99ce-4eed-e09a-da4fd6cebb56"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "import io\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mn4-BuViiiL",
        "outputId": "cfdab730-8021-4ed0-f87b-cd30f24f200a"
      },
      "source": [
        "import pathlib\r\n",
        "text_dir = pathlib.Path('drive/MyDrive/Text')\r\n",
        "for dir in text_dir.iterdir():\r\n",
        "  print(str(dir))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/Text/dinos.txt\n",
            "drive/MyDrive/Text/text_generation_gutenberg.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBoIUMnSi5Yv",
        "outputId": "5f65a8a5-9a96-4385-d5f4-46c86513acf0"
      },
      "source": [
        "text_path = os.path.join(text_dir, \"dinos.txt\")\r\n",
        "print(text_path)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive/MyDrive/Text/dinos.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ81ocoPjLTu",
        "outputId": "0896ee7f-6307-4f3b-f307-fb2d3c90eefd"
      },
      "source": [
        "text = open(text_path, encoding='UTF-8').read().strip()\r\n",
        "print(text[:20])\r\n",
        "text_list = text.split(\"\\n\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aachenosaurus\n",
            "Aardon\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TIqK2i8nX14",
        "outputId": "b197db57-a2d4-4817-ee85-60aa2a66f70b"
      },
      "source": [
        "num_examples = len(text_list)\r\n",
        "print(\"Number of examples : %d\"%num_examples)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of examples : 1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jd7_J7G3kdpu",
        "outputId": "e1fa8298-788b-40a0-84fb-5421d1f414e5"
      },
      "source": [
        "vocab = sorted(set(text))\r\n",
        "print(vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi4CAlb8k4LH",
        "outputId": "a6e9dea1-221a-4560-cd2a-ba1ca593985e"
      },
      "source": [
        "print(\"{} characters in vocabulary\".format(len(vocab)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "53 characters in vocabulary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo0h7GxTlAL4",
        "outputId": "13671c52-4bee-4a16-e417-d1217946438d"
      },
      "source": [
        "char2idx = {u:i for i, u in enumerate(vocab)}\r\n",
        "\r\n",
        "for char, _ in zip(char2idx, range(20)):\r\n",
        "  print(\"{:4s} : {:3d}\".format(repr(char), char2idx[char]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'\\n' :   0\n",
            "'A'  :   1\n",
            "'B'  :   2\n",
            "'C'  :   3\n",
            "'D'  :   4\n",
            "'E'  :   5\n",
            "'F'  :   6\n",
            "'G'  :   7\n",
            "'H'  :   8\n",
            "'I'  :   9\n",
            "'J'  :  10\n",
            "'K'  :  11\n",
            "'L'  :  12\n",
            "'M'  :  13\n",
            "'N'  :  14\n",
            "'O'  :  15\n",
            "'P'  :  16\n",
            "'Q'  :  17\n",
            "'R'  :  18\n",
            "'S'  :  19\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmjoFlSnqK19",
        "outputId": "1a3b25e6-0428-4575-ef61-81dd80a48362"
      },
      "source": [
        "print(char2idx)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 0, 'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7, 'H': 8, 'I': 9, 'J': 10, 'K': 11, 'L': 12, 'M': 13, 'N': 14, 'O': 15, 'P': 16, 'Q': 17, 'R': 18, 'S': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26, 'a': 27, 'b': 28, 'c': 29, 'd': 30, 'e': 31, 'f': 32, 'g': 33, 'h': 34, 'i': 35, 'j': 36, 'k': 37, 'l': 38, 'm': 39, 'n': 40, 'o': 41, 'p': 42, 'q': 43, 'r': 44, 's': 45, 't': 46, 'u': 47, 'v': 48, 'w': 49, 'x': 50, 'y': 51, 'z': 52}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9sYb7Pdlt_H",
        "outputId": "07ec6f6f-4f45-451e-cbb5-cad40adfd3fe"
      },
      "source": [
        "idx2char = np.array(vocab)\r\n",
        "print(\"char at 10th index : %s\"%idx2char[10])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "char at 10th index : J\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9K-S6eCl8mI",
        "outputId": "7d2e3bca-5791-41ba-a4b7-79747a85cbc7"
      },
      "source": [
        "print(idx2char)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n' 'A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q'\n",
            " 'R' 'S' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i'\n",
            " 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxh6X3oAts1D"
      },
      "source": [
        "def create_dataset(text_list):\r\n",
        "  text_list = [[c for c in name] for name in text_list]\r\n",
        "  return text_list\r\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AboruXgrmwfN"
      },
      "source": [
        "def tokenize(lang):\r\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='', char_level=True)\r\n",
        "  lang_tokenizer.fit_on_texts(lang)\r\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\r\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding=\"post\")\r\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u0lnT4Dtndc"
      },
      "source": [
        "def load_dataset(text_list):\r\n",
        "  text_list = create_dataset(text_list)\r\n",
        "  tensor, lang = tokenize(text_list)\r\n",
        "  return tensor, lang"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNaYO8gbunDl"
      },
      "source": [
        "input_tensor, inp_lang = load_dataset(text_list)\r\n",
        "max_length_input = input_tensor.shape[1]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSKqN8PCvCny",
        "outputId": "a3b2f5ce-13a1-4cd6-83de-fea218d785b8"
      },
      "source": [
        "print(\"Max input sequence length : {}\".format(max_length_input))\r\n",
        "print(\"Total number of examples : %d\"%input_tensor.shape[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max input sequence length : 26\n",
            "Total number of examples : 1536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eujIVTsivL1z"
      },
      "source": [
        "def convert(lang, tensor):\r\n",
        "  for t in tensor:\r\n",
        "    if t!=0:\r\n",
        "      print(\"{} -- > {}\".format(t, lang.index_word[t]))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpEjhMfwwoZT",
        "outputId": "5d1e95c4-d056-4647-8272-d677f07c27a4"
      },
      "source": [
        "print(\"Input language; index to char mapping\")\r\n",
        "convert(inp_lang, input_tensor[0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input language; index to char mapping\n",
            "1 -- > a\n",
            "1 -- > a\n",
            "13 -- > c\n",
            "12 -- > h\n",
            "8 -- > e\n",
            "6 -- > n\n",
            "4 -- > o\n",
            "2 -- > s\n",
            "1 -- > a\n",
            "3 -- > u\n",
            "5 -- > r\n",
            "3 -- > u\n",
            "2 -- > s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaPOSUoDwzrL"
      },
      "source": [
        "def split_input_target(seq):\r\n",
        "  input = seq[:-1]\r\n",
        "  target = seq[1:]\r\n",
        "  return input, target"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSaqjyu6x_HW",
        "outputId": "c1836055-6805-4922-8a03-98b4729f42dd"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(input_tensor)\r\n",
        "\r\n",
        "for input in dataset.take(5):\r\n",
        "  name=[]\r\n",
        "  for i in input.numpy():\r\n",
        "    if i!=0:\r\n",
        "      name.append(inp_lang.index_word[i])\r\n",
        "  print(''.join(name))\r\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "aachenosaurus\n",
            "aardonyx\n",
            "abdallahsaurus\n",
            "abelisaurus\n",
            "abrictosaurus\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUGX_QGNyaG0"
      },
      "source": [
        "dataset = dataset.map(split_input_target)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goWKq64R0Qy-"
      },
      "source": [
        "def display(input_batch):\r\n",
        "   inp=[]\r\n",
        "   for i in input_batch.numpy():\r\n",
        "      if i!=0:\r\n",
        "        inp.append(inp_lang.index_word[i])\r\n",
        "   return(''.join(inp))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1o43pam0o6e",
        "outputId": "63da3204-3dd9-4b1c-d481-f6f6a894e8ca"
      },
      "source": [
        "BATCH_SIZE=64\r\n",
        "BUFFER_SIZE = input_tensor.shape[0]\r\n",
        "units = 1024\r\n",
        "embedding_dim=256\r\n",
        "vocab_size = len(inp_lang.word_index) + 1\r\n",
        "\r\n",
        "dataset = dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\r\n",
        "\r\n",
        "dataset"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 25), (64, 25)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUOLLUGT2P-O",
        "outputId": "3d7d2bbb-8cd4-41ff-cf84-0a4b7adddf1e"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\r\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 25]), TensorShape([64, 25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9beXhGLF3Hrg"
      },
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\r\n",
        "  model= Sequential([\r\n",
        "                     layers.Embedding(vocab_size, embedding_dim,\r\n",
        "                                      batch_input_shape=[batch_size,None]),\r\n",
        "                     layers.GRU(rnn_units,\r\n",
        "                                return_sequences=True,\r\n",
        "                                stateful=True,\r\n",
        "                                recurrent_initializer='glorot_uniform'),\r\n",
        "                     layers.Dense(vocab_size)\r\n",
        "  ])\r\n",
        "  return model"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WALfCme4oMS"
      },
      "source": [
        "model = build_model(vocab_size,\r\n",
        "                    embedding_dim,\r\n",
        "                    units,\r\n",
        "                    BATCH_SIZE)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ge7yX2ka4_tK",
        "outputId": "a3f6344d-59f9-4d4e-d4a8-8387d775d093"
      },
      "source": [
        "example_batch_predictions = model(example_input_batch)\r\n",
        "print(example_batch_predictions.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 25, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bg7PvqAj5STe",
        "outputId": "552d553a-dcc2-4bde-cf4c-2085a476f659"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 256)           6912      \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 1024)          3938304   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 27)            27675     \n",
            "=================================================================\n",
            "Total params: 3,972,891\n",
            "Trainable params: 3,972,891\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqikrSBq6Zac",
        "outputId": "dd7c072b-a858-4426-fdf5-ac5e07e9ad87"
      },
      "source": [
        "sample_indices=tf.random.categorical(example_batch_predictions[0], num_samples=1)\r\n",
        "print(sample_indices.shape)\r\n",
        "sample_indices = tf.squeeze(sample_indices, axis=-1)\r\n",
        "print(sample_indices.shape)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25, 1)\n",
            "(25,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0Y6Rvfa5VtT",
        "outputId": "da3a057a-9ed5-4556-d4fa-a40ed8b83cb4"
      },
      "source": [
        "print(\"Sample Input : \",display(example_input_batch[0]))\r\n",
        "print(\"Predictions : \",display(sample_indices))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample Input :  kuszholia\n",
            "Predictions :  ghrfhfujnxsebznubaefdnfk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5kvD-w58CdY",
        "outputId": "ed55c475-12f9-47c1-963d-8a566715ed99"
      },
      "source": [
        "example_input_batch[0].shape, sample_indices.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([25]), TensorShape([25]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9y9bdql8vqz",
        "outputId": "32f15037-1c6a-429a-a096-9989a49952e7"
      },
      "source": [
        "def loss(label, logits):\r\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(label, logits, from_logits=True)\r\n",
        "\r\n",
        "example_batch_loss = loss(example_target_batch, example_batch_predictions)\r\n",
        "print(\"Predictions Shape : \", example_batch_predictions.shape)\r\n",
        "print(\"Scalar losss : \", example_batch_loss.numpy().mean())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predictions Shape :  (64, 25, 27)\n",
            "Scalar losss :  3.302452\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCu3xamOCXq6"
      },
      "source": [
        "checkpoint_dir = \"./checkpoints\"\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\r\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_prefix,\r\n",
        "    save_weights_only=True\r\n",
        ")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzKXIE7JC6gm"
      },
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-76pwaqDCmV",
        "outputId": "8ca99b39-6032-4d15-ff53-f15f770e291c"
      },
      "source": [
        "EPOCHS=10\r\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "24/24 [==============================] - 1s 10ms/step - loss: 2.9293\n",
            "Epoch 2/10\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 1.3006\n",
            "Epoch 3/10\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 1.1123\n",
            "Epoch 4/10\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.9577\n",
            "Epoch 5/10\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.9083\n",
            "Epoch 6/10\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.8631\n",
            "Epoch 7/10\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.8375\n",
            "Epoch 8/10\n",
            "24/24 [==============================] - 0s 9ms/step - loss: 0.8269\n",
            "Epoch 9/10\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.7935\n",
            "Epoch 10/10\n",
            "24/24 [==============================] - 0s 10ms/step - loss: 0.7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7GPww8RKDOML",
        "outputId": "6d2f3f8f-8d73-4111-dc29-c67903062344"
      },
      "source": [
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./checkpoints/ckpt_10'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sf1MD754Ej4Z",
        "outputId": "afaac326-c98f-458a-bce6-4545ad89dca8"
      },
      "source": [
        "model = build_model(vocab_size, embedding_dim, units, batch_size=1)\r\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\r\n",
        "model.build(tf.TensorShape([1,None]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
            "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
            "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vp_FZuNvE3Yz",
        "outputId": "4908a2e3-7381-448a-c45b-36058673c08e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (1, None, 256)            6912      \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (1, None, 1024)           3938304   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (1, None, 27)             27675     \n",
            "=================================================================\n",
            "Total params: 3,972,891\n",
            "Trainable params: 3,972,891\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VPQs4LhE5vb"
      },
      "source": [
        "def generate(model, start_char):\r\n",
        "  num_generate = max_length_input -1\r\n",
        "\r\n",
        "  input_eval= [inp_lang.word_index[start_char]]\r\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\r\n",
        "\r\n",
        "  text_generated=[]\r\n",
        "\r\n",
        "  temperature = 1.0\r\n",
        "\r\n",
        "  model.reset_states()\r\n",
        "\r\n",
        "  for i in range(num_generate):\r\n",
        "    predictions = model(input_eval)\r\n",
        "    predictions = tf.squeeze(predictions, 0)\r\n",
        "    predictions = predictions/temperature\r\n",
        "    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\r\n",
        "    input_eval = tf.expand_dims([predicted_id],0)\r\n",
        "    if(predicted_id!=0):\r\n",
        "      text_generated.append(inp_lang.index_word[predicted_id])\r\n",
        "  return start_char+''.join(text_generated)\r\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0TzX5ukKGlOE",
        "outputId": "1685182f-934c-48f3-fe46-cdef75cff80f"
      },
      "source": [
        "print(generate(model, start_char=u'd'))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dadfysaurus\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}